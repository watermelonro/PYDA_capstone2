# PYDA_capstone2 15조
**BRANCH CRAWLER**

**<original_code.py --> width_price_crawling.py 업데이트 사항>**
캡스톤디자인1 수업시간에 짠 original_code.py에선 클롤링한 상가이름, 월임대료, 면적을 엑셀에 넣을 때 행을 상가이름의 인덱스로 잡았는데 상가이름이 같은 연속된 두 데이터가 존재해서 첫번째 데이터가 입력이 안 되고 한 행이 건너뛰어지는 것을 확인했다. 따라서 width_price_crawling.py에선 인덱스가 중복되지 않도록 설정해서 행이 누락되는 것 없도록 코드를 짰다.

아래는 코드를 돌려야하는 순서와 같다.

<code 폴더>

(1) **total_passengers.py** : 

서울교통공사에서 공개한 시간대별 역별 승하차인구수 데이터를 이용했다.

2015년 1월부터 2023년 10월까지 일자별 모든 시간대의 승하차인구수를 더하는 작업을 엑셀로 1차 작업했다.
판다스의 groupby를 이용해 승하차인구수를 각 호선별 역별을 그룹화하고 평균 계산해 1일당 승하차인구수를 구했다.

결과: **승하차_인구수.xlsx**

(2) **width_price_crawlingcode.py** : 

서울교통공사에서 호선별 역별 각 상가의 면적과 월임대료를 크롤링했다.

결과: **면적_월임대료_돌려서 나온거.xlsx**

(3) **remove_duplicate_store_numbers.py** : 

면적_월임대료_돌려서 나온거.xlsx를 보면 상가번호가 같은 상가가 두번 나오는것이 존재했다. 두번 나온것중 둘 중 하나에는 월임대료가 나와있지 않거나 둘다 나와있지 않거나 둘다 나와있거나 면적이 둘다 나와있지 않은 경우 존재했다.
먼저 상가이름의 값이 같은 두 행 중에서, 월임대료의 값이 '원'이거나 값이 없으면 해당 행을 제거했다.
그 다음 상가이름의 값이 같은 두 행 중에서, 월임대료의 값이 같으면 첫 번째 나오는 행을 남기고 나머지 중복된 행을 제거했다.
마지막으로 상가이름의 값이 같은 두 행 중에서, 면적의 값이 같으면 첫 번째 나오는 행을 남기고 나머지 중복된 행을 제거했다.

결과: **면적_월임대료_상가번호 중복 제거(최종).xlsx**

(4) **number_of_shops_in_use.py** : 

면적_월임대료_상가번호 중복 제거(최종).xlsx에서 상가이름을 기준으로 그룹화하고 각 그룹의 개수를 셌다.

결과: **사용상가수_돌려서 나온거.xlsx**

<data폴더>

(1) **승하차_인구수.xlsx**

(2) **면적_월임대료_돌려서 나온거.xlsx**

(3) **면적_월임대료_상가번호 중복 제거(최종).xlsx**

(4) **사용상가수_돌려서 나온거.xlsx**

(5) **사용상가수_합산 합친거.xlsx** : 

면적_월임대료_상가번호 중복 제거(최종).xlsx를 보면 여러 상가를 합쳐서사용하는 상가 합산이라고 나와있고 또한 스마트팜, 창업카페 등 상가번호가 호수가 아닌 상가가 소수 존재한다.
사용상가수_돌려서 나온거.xlsx 에 각 역마다 합산 상가 수는 더하고 상가번호가 호수가 아닌 상가의 수는 빼주는 작업을 진행했다.

(6)**상가수_환승역수.xlsx** : 일일이 구했다.

(7)**상가업종.xlsx** : 서울열린데이터광장에서 공개한 상가업종데이터를 이용했다.



**BRANCH PRE**

**기존에 했던 전처리 과정**

기존에는 로지스틱 회귀 분석을 위한 테이블을 만들기 위해,  크롤링한 데이터와 공공데이터포탈에서 가져온 데이터를 엑셀로 정리했다. 당시에는 필요한 데이터가 들어있는 엑셀 파일에서 필요한 데이터만 복사해서 새로운 엑셀 파일에 붙여넣었고 공실 수, 공실률, 환승역 수 1개마다 이용하는 승하차인원은 엑셀 함수를 사용하여 계산했다. 또한 로지스틱 회귀분석을 사용하기 위해 공실률 75% 이상을 0, 공실률 20% 이하를 1로 하나하나 공실률을 보면서 데이터를 입력했다. 

그리고 상가 업종과 공실률의 상관관계 알아보고 싶었는데, 당시에는 지하철역 상가의 상가업종 데이터가 없어 서울교통공사에 데이터를 요청한 상태로 마무리했다.

**현재 전처리 과정**

현재는 필요한 데이터가 들어있는 엑셀 파일을 pandas를 통해 간단한 코드로 필요한 데이터가 들어있는 테이블을 만들었다.

아래는 코드를 돌려야하는 순서와 같다.

**(1)** 
**number1_mall_transfer_pre.py : 상가 수와 환승역 수가 들어있는 코드**

**number2_mall_use_pre.py : 사용 상가 수가 들어있는 코드**

**number3_passenger_pre.py :  승하차인구 수가 들어있는 코드**

- 지하철역 이름 형식 통일 : 수작업 → 역 서브명 삭제 코드, 역 뒤의 (호선 숫자) 삭제 코드, ‘ㅇㅇ역’에서 ‘역’ 삭제 코드
- 필요한 데이터만 남기기 : (기존) 필요한 데이터만 바로 가져와 테이블에 붙여넣기 → (현재) df.drop으로 필요한 데이터 열만 남기거나 필요한 열만 가져오기
- 필요한 데이터끼리 합치기 : (기존) 지하철역 이름을 정렬하고 데이터 붙여넣기 → (현재) 지하철역 열을 기준으로 merge
- 같은 역의 승하차인구수 더하기 : (기존) 엑셀 함수로 같은 역의 승하차인구 수 더하기 → (현재) groupby와 sum을 사용해 지하철 역을 기준으로 승하차인구수 수 더하기
- 역마다 공실률이 높은 역에는 0, 공실률이 낮은 역에는 1 : 공실률을 보고 엑셀에 하나하나 입력 → 새로운 열을 만들고 공실률의 상위, 하위 10%씩 나눠서 0과 1을 입력하는 코드 사용

**(2) number4_interrelation.py : 상관관계 분석 테이블을 만드는 코드**

- 0도 1도 해당하지 않는 역 빼고 테이블 만들기 : (기존) 0과 1에 해당하는 역만 복사해서 새로운 엑셀 파일 생성 → (현재) 0과 1에 해당하는 역들만 가져와 데이터 프레임 생성
- 필요한 데이터를 언제든 가져와 쓸 수 있도록 상가 수-환승역, 사용 상가 수, 승하차 인구 수 월임대료가 들어있는 데이터프레임을 하나씩 각각 생성하고 pickle이라는 라이브러리를 가져와 다른 파일에서도 쓸 수 있게 함.
- 상관관계 분석 : (기존) 상관관계 분석 계획만 세움 → (현재) 상관관계 분석에 필요한 상가업종 데이터를 받아서 상관관계 분석 테이블 생성과 모델 생성

**(3) number5_rent_fee_pre.py : 월임대료 들어있는 코드**

**(4) number6_linear.py : 선형회귀 분석 테이블을 만드는 코드**

- 선형회귀 분석 : (기존) 월임대료와 공실률 상관관계 엑셀로 확인 → (현재)선형회귀 분석 테이블 생성과 모델 생성

**(5) number7_logistic.py : 로지스틱 분석 테이블을 만드는 코드**

- 로지스틱 분석 : (기존) 로지스틱 분석 계획만 세움 → (현재) 로지스틱 분석 테이블 생성과 모델 생성

  

**BRANCH MODEL**
순서는 modeling.ipynb에 써있는 순서와 같다.

**(1) 상관관계_테이블.xlsx 데이터를 이용하여 승하차인구수와 공실률의 상관관계를 확인하였다.**

- 피어슨 상관계수는 -1에서 1 사이의 값을 가지며 1에 가까울수록 양의 상관관계가 강하고, -1에 가까울수록 음의 상관관계가 강하다. 일반적으로 0.1에서 0.3 사이는 약한 상관관계를 가지고 있다고 하는데, 승하차인구수와 공실률은 -0.25로 약한 음의 상관관계를 가지고 있다.
- 

**(2) 선형회귀_테이블.xlsx 데이터를 이용하여 월 임대료와 공실률의 선형관계를 확인 하였다.**
상관관계도 확인하였는데 월 임대료와 공실률의 상관관계는 0.15로 매우 낮았다.

- 해당 모델은 R-squared가 0.079로 설명력이 거의 없고 컬럼의 p-value가 0.15로 유의한 컬럼이 아니다.
- 선형관계를 가지고 있지 않다

**(3) 로지스틱_테이블.xlsx 데이터를 이용하여 공실여부(y)와 승하차인구수, 환승역수, 1제곱미터당 평균 월 임대료들을 이용하여 회귀분석을 해보았다.**

- 데이터의 개수가 너무 적어 유의미하게 예측하는데에 한계가 있다.
- 해당 모델은 r-squared가 0.078밖에 되지 않아 설명력이 매우 낫고 각 칼럼의 p-value도 0.05보다 작지 않기에 유의한 컬럼들이 아니다.
